{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:10:11.356301494Z",
     "start_time": "2023-06-10T14:10:11.327279800Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from classifiers import create_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup configuration variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:10:11.442234646Z",
     "start_time": "2023-06-10T14:10:11.340386214Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:16:15.691671111Z",
     "start_time": "2023-06-10T14:16:15.286630870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 16:16:15.573213: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('csv_files/merged_df_with_dates.csv', sep=',')\n",
    "attack_type = 'no_attack'\n",
    "\n",
    "y = df['is_malware']\n",
    "X = df.drop('is_malware', axis=1).select_dtypes(include=['int', 'float']).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data into Tensors\n",
    "X_train = tf.constant(X_train, dtype=tf.float32)\n",
    "y_train = tf.constant(y_train, dtype=tf.int32)\n",
    "X_test = tf.constant(X_test, dtype=tf.float32)\n",
    "y_test = tf.constant(y_test, dtype=tf.int32)\n",
    "\n",
    "# Simulate the clients' data\n",
    "client_data = []\n",
    "for i in range(NUM_CLIENTS):\n",
    "    start = i * len(X_train) // NUM_CLIENTS\n",
    "    end = (i + 1) * len(X_train) // NUM_CLIENTS\n",
    "    client_data.append(\n",
    "        tf.data.Dataset.from_tensor_slices((X_train[start:end], y_train[start:end])).batch(1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare client models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-10T16:30:05.314723594Z",
     "start_time": "2023-06-10T16:29:42.927068347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 18:29:45.704490: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:45.705908: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:45.777509: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:45.777654: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.630004: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.630165: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.810798: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.810946: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.820894: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.821071: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.832225: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.832332: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.855125: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.855285: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.890716: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.890833: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.906339: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.906501: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.929297: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.929486: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.950839: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.950954: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.965101: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.965274: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.969318: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.969461: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.977096: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.977320: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:46.988812: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:46.988932: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-06-10 18:29:47.040611: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-06-10 18:29:47.040735: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('binary_accuracy', 0.8847164), ('loss', 0.29796183), ('num_examples', 12569), ('num_batches', 12569)])\n",
      "OrderedDict([('binary_accuracy', 0.9189275), ('loss', 0.22824213), ('num_examples', 12569), ('num_batches', 12569)])\n",
      "OrderedDict([('binary_accuracy', 0.9226669), ('loss', 0.21991591), ('num_examples', 12569), ('num_batches', 12569)])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 32\u001B[0m\n\u001B[1;32m     29\u001B[0m         state \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mstate\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28mprint\u001B[39m(result\u001B[38;5;241m.\u001B[39mmetrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclient_work\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 32\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfederated_averaging_process\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNUM_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mNUM_ROUNDS\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 28\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(federated_averaging_process, num_clients_per_round, num_rounds)\u001B[0m\n\u001B[1;32m     25\u001B[0m sampled_clients \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(\u001B[38;5;28mrange\u001B[39m(NUM_CLIENTS), size\u001B[38;5;241m=\u001B[39mnum_clients_per_round, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     26\u001B[0m sampled_train_data \u001B[38;5;241m=\u001B[39m [federated_data[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m sampled_clients]\n\u001B[0;32m---> 28\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfederated_averaging_process\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampled_train_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m state \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mstate\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(result\u001B[38;5;241m.\u001B[39mmetrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclient_work\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/PycharmProjects/android_binary_backdoor/venv/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py:139\u001B[0m, in \u001B[0;36mConcreteComputation.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    138\u001B[0m   arg \u001B[38;5;241m=\u001B[39m function_utils\u001B[38;5;241m.\u001B[39mpack_args(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_type_signature\u001B[38;5;241m.\u001B[39mparameter, args, kwargs)\n\u001B[0;32m--> 139\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_context_stack\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/android_binary_backdoor/venv/lib/python3.10/site-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py:65\u001B[0m, in \u001B[0;36mSyncExecutionContext.invoke\u001B[0;34m(self, comp, arg)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\u001B[38;5;28mself\u001B[39m, comp, arg):\n\u001B[0;32m---> 65\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_async_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_coro_and_return_result\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_async_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcomp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/android_binary_backdoor/venv/lib/python3.10/site-packages/tensorflow_federated/python/common_libs/async_utils.py:149\u001B[0m, in \u001B[0;36mAsyncThreadRunner.run_coro_and_return_result\u001B[0;34m(self, coro)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001B[39;00m\n\u001B[1;32m    148\u001B[0m future \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mrun_coroutine_threadsafe(coro, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_loop)\n\u001B[0;32m--> 149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Create the TFF version of the model\n",
    "def model_fn():\n",
    "    keras_model = create_nn(input_shape=(X.shape[1],), compile=False)\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=client_data[0].element_spec,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "# Create the federated data\n",
    "federated_data = [client_data[i] for i in range(NUM_CLIENTS)]\n",
    "\n",
    "# Create the TFF model and federated learning process\n",
    "federated_averaging_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    ")\n",
    "\n",
    "def train(federated_averaging_process, num_clients_per_round, num_rounds):\n",
    "    state = federated_averaging_process.initialize()\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        sampled_clients = np.random.choice(range(NUM_CLIENTS), size=num_clients_per_round, replace=False)\n",
    "        sampled_train_data = [federated_data[i] for i in sampled_clients]\n",
    "\n",
    "        result = federated_averaging_process.next(state, sampled_train_data)\n",
    "        state = result.state\n",
    "        print(result.metrics['client_work']['train'])\n",
    "\n",
    "train(federated_averaging_process, NUM_CLIENTS, NUM_ROUNDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
